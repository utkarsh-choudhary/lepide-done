{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66ad2f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c04c0ad6be4ff6bc2c7ed814b29875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piyush\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Piyush\\.cache\\huggingface\\hub\\models--Falconsai--text_summarization. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d4cf2c18e0472e9a55169cce220847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3061f076efcc45c0a486cccf0eee92ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab06692a8e546ca9f183ad6fb6a8a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d555883cc648d18c552c5c9904367c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc6efdc7e204d82ae6c945e65650a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4aea370627c48c0a5b14b21f6e7f0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the document:\n",
      "IEEE Image Classification Using Convolutional Neural Network Piyush Singh Bora Department of Computer Science & Engineering Lovely Professional University Punjab, India piyushbora63 @gmail.com Abstract—In recent years, research related to images is a challenging task as there are very few techniques which can be used in processing and classification of images. Deep Learning has emerged as a new area in machine learning and is applied to a number of signals and image applications. In this paper, we have briefly discussed different CNN architectures\n"
     ]
    }
   ],
   "source": [
    "#model 1 using falconsai's text summarization model\n",
    "import PyPDF2\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Step 1: Extract Text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "                else:\n",
    "                    print(f\"Warning: No text extracted from page {reader.pages.index(page) + 1} in {pdf_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {str(e)}\")\n",
    "    return text\n",
    "\n",
    "# Step 2: Load the Falcon text summarization model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Falconsai/text_summarization\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Falconsai/text_summarization\")\n",
    "\n",
    "# Step 3: Summarize the Extracted Text\n",
    "def summarize_text(text, max_length=130, min_length=30):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Specify the path to the PDF file\n",
    "pdf_file = 'RK20UNB38PiyushSinghBora.pdf'\n",
    "\n",
    "# Extract text from the PDF\n",
    "extracted_text = extract_text_from_pdf(pdf_file)\n",
    "\n",
    "# Summarize the extracted text\n",
    "summary = summarize_text(extracted_text)\n",
    "\n",
    "# Print the summary\n",
    "print(\"Summary of the document:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e2b07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2163f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "604585a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXX -X-XXXX -XXXX -X/XX/$XX.00 ©20XX IEEE  Image Classification Using Convolutional Neural \n",
      "Network  \n",
      " \n",
      "Piyush Singh Bora  \n",
      "Department of Computer Science & \n",
      "Engineering   \n",
      "Lovely Professional University  \n",
      "Punjab , India  \n",
      "piyushbora63 @gmail.com   \n",
      "Abstract—In recent years, research related to images is a \n",
      "challenging task as there are very few techniques which can be \n",
      "used in processing and classification of images. Image \n",
      "classification is referred as Classification of the images from \n",
      "many predefined categorie s. Deep Learning has emerged as a \n",
      "new area in machine learning and is applied to a number of \n",
      "signals and image applications. C onvolutional Neural Network \n",
      "(CNN) is the state -of-the-art for image classification task. Here \n",
      "we have briefly discussed different components of CNN. In this \n",
      "paper, we have explained different CNN architectures for image \n",
      "classification.  We have discussed the model description and \n",
      "training details of each model.  Here we will have the \n",
      "implementation of CNN on INTEL Image Classification Dataset \n",
      "taken from Kaggle. This is image data of Natural Scenes around \n",
      "the world.  \n",
      "Keywords —Deep Learning, Convolutional neural networks, \n",
      "Image Classification , insert ( key words ) \n",
      "I. INTRODUCTION (HEADING 1) \n",
      "Due to the spectacular growth in the digital world,  image \n",
      "recognition and classification became one of the  tough \n",
      "challenges in computer vision. Computer Vision (CV)  is a \n",
      "computer science field that works in enabling computers  to \n",
      "view,  identify, and process images in the same manner as  \n",
      "Human vision does, and then deliver appropriate output. In  the \n",
      "time being the need of high accuracy in computer vision  also \n",
      "increased. It took decades for the computer scientists t o get \n",
      "where we are now.  \n",
      "Present computer vision is used in many fields like Vision  \n",
      "biometrics, Object recognition, Social Media, Smart cars an d \n",
      "many more. In many of these image recognition and  \n",
      "classification plays a major role. In simpler terms, Image  \n",
      "recognition is how well com puter can recognize objects,  \n",
      "writings, actions, places. And image classification is  \n",
      "classification of images based on the contextual information  \n",
      "in images.  \n",
      "In computer vision, most of the times the  information is in \n",
      "the form of non -textual form, such as  images.[1] Due to the \n",
      "presence such a huge number of  images the image databases \n",
      "also increased.  As a result, we face complex task of organizing \n",
      "and accessing vast amounts of images that are available. \n",
      "Image  classification helps in solving such tasks.  \n",
      "Convolu tional Neural Network (CNN or ConvNet) is a  \n",
      "especial type of multi -layer neural network inspired by the  \n",
      "mechanism of the optical system of living creatures. Hubel  \n",
      "and Wiesel [4] discovered that animal visual cortex cells \n",
      "detect  light in the small receptive  field. Motivated by this \n",
      "work,  in 1980, Kunihiko Fukushima introduced neocognitron \n",
      "[5] which is a multi -layered neural network capable of  \n",
      "recognizing  visual pattern hierarchically through learning. \n",
      "This network is  considered as the theoretical inspiration for \n",
      "CNN. In 1990 , LeCun et al. introduced the practical model of \n",
      "CNN  and developed LeNet -5 [8]. Training by \n",
      "backpropagation  algorithm helped LeNet -5 recognizing visual \n",
      "patterns from  raw pixels directly without using any separate \n",
      "feature enginee ring mechanism. Also fewer connections and \n",
      "parameters  of CNN than conventional feedforward neural \n",
      "networks with  similar network size, made model training \n",
      "easier. But at that  time in spite of several advantages, the \n",
      "performance of CNN  in intricate problems such as \n",
      "classification of high -resolution  image, was limited by the \n",
      "lack of large training data, lack of  better regularization method \n",
      "and inadequate computing power . \n",
      "Nowadays we have larger datasets with millions of high  \n",
      "resolution labelled data of thousan ds category like ImageNet, \n",
      "LabelMe etc. With the advent of powerful GPU  machine and \n",
      "better regularization method, CNN delivers out -standing \n",
      "performance on image classification tasks. In 2012 a  large \n",
      "deep convolution neural network, called AlexNet , designed  by \n",
      "Krizhevsky et al. showed excellent performance  on the \n",
      "ImageNet Large Scale Visual Recognition Challenge  \n",
      "(ILSVRC) . The success of AlexNet has become the  \n",
      "inspiration of different CNN model such as ZFNet,  VGGNet, \n",
      "GoogleNet , ResNet , DenseNet,  CapsNet , SENet etc in the \n",
      "following years.  In this study, we have tried to give a review \n",
      "of the advancements of the CNN in the area of image \n",
      "classification. We  have given a general view of CNN \n",
      "architectures in section  II. Section III describes architecture \n",
      "and trai ning details of  different models of CNN . \n",
      " \n",
      "II. CONVOLUTIONAL  NEURAL  NETWORK  \n",
      " ANN is a Neural Network which is constructed  \n",
      "based on the Biological Neural Network[26]. Its main idea is  \n",
      "taken from the Cognitive  science [13] where many simple  \n",
      "Computational units are connected for intelligent behaviors.  \n",
      "But due to its disadvantage of not having large  computational \n",
      "power CNN is introduced. Image analysis i s most common \n",
      "use of CNN . A typical CNN is composed of singl e or multiple \n",
      "blocks of  convolution and sub -sampling layers, after that one \n",
      "or more  fully connected layers and an output layer as shown \n",
      "in figure . \n",
      " \n",
      "Convolutional neural Network has hidden layers, Known \n",
      "as Convolutional layers which make CNN more effective  for \n",
      "image analysis.  CNN layer types mainly include three types \n",
      "[14] as shown in  \n",
      "the Figure 1:  \n",
      " Convolutional layer  \n",
      " Pooling layer  \n",
      " Fully connected layer  \n",
      "When a computer sees image, it converts the image into  an \n",
      "array of pixel values depending on the im age resolution  and \n",
      "size. Let’s consider an image of type of jpg and size be  480 x \n",
      "480. Then its converted to 480 x 480 x 3 image where  the \n",
      "represents the RBG values. To describe the intensity  of the \n",
      "pixel, they are given numbering from 0 to 255.  Further th e \n",
      "array with numbers are given as input to the  image \n",
      "classification . \n",
      "A. Convolutional Layer  \n",
      "The convolutional layer (conv layer) is the central part of  \n",
      "a CNN. Images are generally stationary in nature. That means  \n",
      "the formation of one part of the image is same  as any other  \n",
      "part. So, a feature learnt in one region can match similar  \n",
      "pattern in another region. In a large image, we take a small  \n",
      "section and pass it through all the points in the large image  \n",
      "(Input). While passing at any point we convolve them into a  \n",
      "single position (Output). Each small section of the image that  \n",
      "passes over the large image is called filter (Kernel). The filters  \n",
      "are later configured based on the back propagation technique.  \n",
      "Figure 2 shows typical convolutional operation . \n",
      " \n",
      " \n",
      "B. Sub-sampling or Pooling Layer  \n",
      "A problem with the output of the Conv layer is that they  \n",
      "are sensitive to the location of the features in the input.  One \n",
      "idea to reduce the sensitivity is that we can decrease its  \n",
      "dimensionality i.e., down sampling. Pooling la yer is used to  \n",
      "decrease the dimensions of the feature map. There are two  \n",
      "types of common pooling techniques that can be used to  \n",
      "decrease the dimensionality. They are max pooling and the  \n",
      "average pooling. In max pooling, calculating the max value  \n",
      "of each pat ch in the feature map. Whereas average pooling,  \n",
      "finding the average of each patch in the feature map. Figure  \n",
      "3 is an example of max pooling . \n",
      " C. Fully Connected layer  \n",
      "The task of the fully connected layer is to connect the  \n",
      "output of the previous layer. There  is no spatial arrangement \n",
      "in this layer. There can be many fully connected layers  where \n",
      "the last layer is connected to the output layer. One of  the most \n",
      "commonly used method is soft regression because  of its \n",
      "performance. Other methods like SVM can also be  used with \n",
      "CNN to solve more complex task.  \n",
      "              \n",
      "III. IMPLEMENTATION OF INTEL IMAGE CLASSIFICATION \n",
      "DATASET  \n",
      "A. About Dataset  \n",
      "This is image data of Natural Scenes around the world.  \n",
      "This Data contains around 25k images of size 150x150 \n",
      "distributed under 6 categories.  \n",
      "'buildings' -> 0  \n",
      "'forest' -> 1  \n",
      "'glacier' -> 2  \n",
      "'mountain' -> 3  \n",
      "'sea' -> 4  \n",
      "'street'                                          ->                                     5 \n",
      "The Train, Test and Prediction data is separated in each zip \n",
      "files. There are aro und 14k images in Train, 3k in Test and 7k \n",
      "in Prediction.  \n",
      "This data was initially published on \n",
      "https://datahack.analyticsvidhya.com  by Intel to host a Image \n",
      "classification Challenge.  \n",
      "Fig 4: Visualizing one image form each class  \n",
      " \n",
      "B. Model Implementation  \n",
      "Sequential model implementation, starting off with the \n",
      "input layer with 32 filters on input shape of [150,150,3]  , \n",
      "kernel size as 3, putting on the activation func tion of ReLU. \n",
      "Adding on the MaxPooling layer with pool size of (2,2). \n",
      "Another Conv2D layer with 64 filters making the \n",
      "convergence, Adding another MaxPooling layer and then \n",
      "Flatten layer to get a single dimensional array. Ending with \n",
      "few Dense layers for ou r neural network.  \n",
      "Fig 5: Model Compilation  \n",
      " \n",
      "C. Model Performance  \n",
      "Accuracy is the archetypal metric in machine learning.  It’s a \n",
      "metric for evaluating model performance for classification \n",
      "tasks and is so well -known that it is often used as a \n",
      "synonym for overall offline and online model performance.  \n",
      "AI accuracy is the percentage of correct classifications that a \n",
      "trained machine learning model achieves, i.e., the number of \n",
      "correct predictions divided by the total number of \n",
      "predictions across all classes .  \n",
      "Here our model attains an accuracy of 0.7826 value.  \n",
      "Fig 6: plot history of loss and accuracy  \n",
      " IV. CONCLUSION  \n",
      "In conclusion, the application of Convolutional Neural \n",
      "Networks (CNNs) for image classification on the Intel \n",
      "Image Dataset obtained from Kaggle has sh own significant \n",
      "promise in the field of computer vision research. \n",
      "Throughout this research paper, we have explored various \n",
      "aspects of this study, and several key findings and \n",
      "takeaways emerge : \n",
      "1. Dataset Analysis : The Intel Image Dataset, \n",
      "containing a diverse  range of images, has provided \n",
      "a solid foundation for training and testing our CNN \n",
      "models. Its inclusivity of scenes like buildings, \n",
      "forests, mountains, and more adds to the real -world \n",
      "applicability of the research.  \n",
      "2. CNN Architectures : Our study revealed th e \n",
      "importance of selecting appropriate CNN \n",
      "architectures, such as VGG, ResNet, or Inception, \n",
      "depending on the complexity of the classification \n",
      "task. The choice of architecture can greatly \n",
      "influence the model's performance.  \n",
      "3. Data Augmentation : Augmentation te chniques, \n",
      "including rotation, scaling, and flipping, proved \n",
      "essential in improving model generalization. Data \n",
      "augmentation helps prevent overfitting and \n",
      "enhances the model's ability to recognize objects \n",
      "from different angles and perspectives.  \n",
      "4. Hyperparamete r Tuning : Fine -tuning \n",
      "hyperparameters, such as learning rates, batch \n",
      "sizes, and dropout rates, can significantly impact \n",
      "the model's performance. Rigorous \n",
      "experimentation is crucial to identify the optimal \n",
      "parameter values.  \n",
      "5. Transfer Learning : Leveraging pre -trained \n",
      "models on larger datasets, particularly for image \n",
      "recognition tasks, can save considerable training \n",
      "time and resources, while often yielding \n",
      "competitive results.  \n",
      "6. Evaluation Metrics : The choice of evaluation \n",
      "metrics, such as accuracy, precision, re call, and F1 -\n",
      "score, must align with the specific requirements of \n",
      "the image classification task. Accuracy is a \n",
      "standard metric but may not be suitable for \n",
      "imbalanced datasets.  \n",
      "7. Challenges and Limitations : Our research also \n",
      "identified some challenges, includi ng the need for \n",
      "substantial computational resources for training \n",
      "large models and handling large datasets. \n",
      "Additionally, overfitting remains a potential \n",
      "concern, especially when working with smaller \n",
      "datasets.  \n",
      "8. Future Directions : To further advance this \n",
      "research, future investigations could focus on \n",
      "exploring the potential of more advanced \n",
      "architectures like Transformers for image \n",
      "classification. Additionally, domain -specific fine -\n",
      "tuning and the incorporation of domain knowledge \n",
      "can improve model performance.  \n",
      "9. Real -world Applications : The results of this study \n",
      "have direct implications for real -world \n",
      " applications, such as autonomous vehicles, \n",
      "surveillance systems, and object recognition in \n",
      "industrial settings, where accurate image \n",
      "classification is critical.  \n",
      "In summary, our research demonstrates that CNNs applied \n",
      "to the Intel Image Dataset from Kaggle can yield highly \n",
      "accurate and effective image classification results. As the \n",
      "field of computer vision continues to evolve, the insights \n",
      "and methodologies outlined i n this paper serve as valuable \n",
      "contributions, fostering further advancements in image \n",
      "recognition and classification. The success of this research \n",
      "highlights the importance of continuous exploration and innovation in the domain of deep learning and compute r \n",
      "vision.  \n",
      "REFERENCES  \n",
      " \n",
      "[1] www.Kaggle.com , A allows users to find datasets they want to use in \n",
      "building AI models, publish datasets, work with other data scientists \n",
      "and machine learning engineers, and enter competitions to solve data \n",
      "science challenges.  \n",
      "[2] Jhttps://www.researchgate.net/publication/275257620_Image_Classifi\n",
      "cation_Using_Convolutional_Neural_Networks . \n",
      "[3] http://www.warse.org/IJETER/static/pdf/file/ijeter308102020.pdf K. \n",
      "Elissa, “Title of paper if known,” unpublished.  \n",
      "[4] Towards Data Science – Convolutio nal Neural Networks  \n",
      " \n",
      " \n",
      "(which is ideally a 300 dpi TIFF or EPS file, with all fonts \n",
      "embedded) because, in an MSW document, this method is \n",
      "somewhat more stable than directly i nserting a picture.  \n",
      "To have non -visible rules on your frame, use the \n",
      "MSWord “Format” pull -down menu, select Text Box > \n",
      "Colors and Lines to choose No Fill and No Line.  \n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            num_pages = len(reader.pages)\n",
    "            for page_num in range(num_pages):\n",
    "                try:\n",
    "                    page = reader.pages[page_num]\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text\n",
    "                    else:\n",
    "                        print(f\"Warning: No text extracted from page {page_num + 1} in {pdf_path}\")\n",
    "                except IndexError:\n",
    "                    print(f\"Error: Page {page_num + 1} is out of range in {pdf_path}.\")\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {str(e)}\")\n",
    "    return text\n",
    "\n",
    "# Specify the path to the PDF file\n",
    "pdf_file = 'RK20UNB38PiyushSinghBora.pdf'\n",
    "\n",
    "# Extract text from the PDF\n",
    "extracted_text = extract_text_from_pdf(pdf_file)\n",
    "\n",
    "# Now, `extracted_text` contains the text extracted from the document.\n",
    "print(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae05b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52f74d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the text generation pipeline with GPT-2\n",
    "summarizer = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "def summarize_text_with_gpt2(text):\n",
    "    # Prompt GPT-2 to summarize the text\n",
    "    prompt = \"Summarize the following text:\\n\" + text + \"\\nSummary:\"\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary = summarizer(prompt, max_length=4000, num_return_sequences=1, do_sample=False)\n",
    "    \n",
    "    # Extract the summary part from the generated text\n",
    "    generated_text = summary[0]['generated_text']\n",
    "    summary_text = generated_text.split(\"Summary:\")[-1].strip()\n",
    "    \n",
    "    return summary_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558dd58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff43e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2 using gpt2\n",
    "\n",
    "# Initialize the text generation pipeline with GPT-2\n",
    "summarizer = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "def summarize_text_with_gpt2(text):\n",
    "    # Prompt GPT-2 to summarize the text\n",
    "    prompt = \"Summarize the following text:\\n\" + text + \"\\nSummary:\"\n",
    "    \n",
    "    # Generate the summary\n",
    "    summary = summarizer(prompt, max_new_tokens=50, num_return_sequences=1, do_sample=False)\n",
    "    \n",
    "    # Check if the summarizer returned any output\n",
    "    if len(summary) == 0 or 'generated_text' not in summary[0]:\n",
    "        return \"No summary generated.\"\n",
    "\n",
    "    generated_text = summary[0]['generated_text']\n",
    "\n",
    "    # Check if \"Summary:\" is in the generated text\n",
    "    if \"Summary:\" in generated_text:\n",
    "        summary_text = generated_text.split(\"Summary:\")[-1].strip()\n",
    "    else:\n",
    "        summary_text = generated_text.strip()  # Fallback if \"Summary:\" is not found\n",
    "\n",
    "    return summary_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663eeff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_document_with_gpt2(pdf_path=None):\n",
    "    if pdf_path:\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "    else:\n",
    "        raise ValueError(\"Please provide a valid document path.\")\n",
    "    \n",
    "    # Summarize the extracted text with GPT-2\n",
    "    summary = summarize_text_with_gpt2(text)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"RK20UNB38PiyushSinghBora.pdf\"\n",
    "#docx_path = \"example.docx\"\n",
    "\n",
    "# Summarize a PDF\n",
    "summary = summarize_document_with_gpt2(pdf_path=pdf_path)\n",
    "\n",
    "print(\"Summary of PDF:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428380f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 3 using facebook bart\n",
    "def summarize_text(pdf_path=None):\n",
    "    if pdf_path:\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "    else:\n",
    "        raise ValueError(\"Please provide a valid document path.\")\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    # Depending on the model and the length of the text, you may need to split the text into smaller chunks\n",
    "    summary = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# Summarize the extracted text\n",
    "pdf_path = \"RK20UNB38PiyushSinghBora.pdf\"\n",
    "\n",
    "summary = summarize_text(pdf_path=pdf_path)\n",
    "\n",
    "print(\"Summary of PDF:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490492be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ff0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
